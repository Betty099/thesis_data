#Firstly, I need to lead data into R in order to run statistical analyses I need data.
install.packages("tidyverse")
load("USFatalities.Rdata")
#I need to load package tidyverse in order to be able to read data and also later to be able to visualize and plot results
#I use function load() to load dataset in R
head(USFatalities)
#head function shows me if the dataet loaded and how its beginning looks like -> it reasures me that loading went well and I can continue with analysis
USFatalities$tax_increase <- as.factor(USFatalities$tax_increase)
#I change tax increase into a factor so I can work with the variable further -> I am overwriting it here in data set so I do not have to rewrite it every time I am writing code and using the variable
#I use tax increase as a variable together with interval for my Diff-in-Diff regression => I use using tax increase to see if tax increase has a impact on fatalities rate
library('plm')
#import plm in order to run panel data - I will use it later but I will load it here
library('car')
#import car library to create panel scatterplot - I will use it later but also load it here
library(ggplot2)
#library for plots and data visualization
library(gplots)
#library for various R programming tools for data plotting
library(ggpubr)
#library for publications ready plots
library(broom)
#library helps to clean up outputs of predictions and estimations and make them into tidy data
library(datasets)
#package from R to summarize datasets and variables
library(dplyr)
#helps with grammar of data manipulation
library(emmeans)
#helps with model estimations and comparisons among groups after fitting
library(forcats)
#library for working with categorical variables
library(graphics)
#library for R graphics
library(grDevices)
#library for colour of graphs
library(quantmod)
#helping with quantitative financial modelling
library(readr)
#helps to read excel and other rectangular text data
library(stats)
#helps to work with statistics
library(stringr)
#support of common string operations
library(tidyquant)
#library for quantitative financial analysis
library(tidyr)
#helps to tidy data
library(tidyverse)
#helps non-programmer to work with data using string commands in R it also contains other packages like ggplot which I called above
plot_violin <- ggplot(USFatalities, aes(x=tax_increase, y=fatal_rate),) + geom_violin()
#this function shows plot in a beautiful violin visualization
#in violin plot I plot tax increase on beer between 1986-1988 and traffic fatality rate.
plot_violin
plotmeans(fatal_rate ~ tax_increase, USFatalities)
#this is function that visualizes means and plots them too
#(STHDA n.d.)
#In plot means I again plot beer tax increase between 1986-1988 and traffic fatality rate as it provides clearer visualization without portraying the full density curves of groups
plotmeans(fatal_rate ~ youngdrivers, USFatalities)
#I am trying to see whether young drivers have higher average of fatality rate accidents in traffic
plotmeans(fatal_rate ~ year, USFatalities)
#I am trying to visualize whether there are differences across years in fatality rates
plotmeans(afatal_rate ~ tax_increase, USFatalities)
#I am trying to see if beertax increase had is related with alcohol related traffic fatalities
box_one <- boxplot(fatal_rate ~ tax_increase, USFatalities)
#here I am running boxplot to see if the assumptions are met
box_one
#here I am calling boxplot to visualize it
#Now, I am doing regression to confirm the correlation between beer tax increase and traffic fatality rate. However I cannot assess the causality from regression results
simple_regression <- lm(fatal_rate ~ tax_increase, USFatalities)
#here I am running simple regression using lm() function
summary(simple_regression)
#summary() function shows me the results of my regression
df_treatment_yes <- subset(USFatalities, tax_increase == TRUE)
#creates a data set which only consist of observations that increased taxes at some point
df_treatment_no <- subset(USFatalities, tax_increase == FALSE)
#creates a data set which only consist of observations that increased taxes at some point
#publications ready plots
t.test(df_treatment_no$fatal_rate, df_treatment_yes$fatal_rate, alternative = "two.sided", var.equal = FALSE)
#As previously explained, here I decided to run again regression to see if alcohol traffic fatality rate decreases or increases with beer tax increase or if it also goes against the economic theory
plotmeans(afatal_rate ~ tax_increase, USFatalities)
#Reminder that plotting beer tax increase difference between state and traffic fatalities showed positive relationship.  Therefore, in this simple regression I changed fatality traffic rate and substitute the variable with traffic fatality rate cause by alcohol influence. I did it in order to see if beer tax increase reduces or increase alcohol fatalities caused by alcohol consumption to show that previous results are indeed influenced by other variables.
regression_two <- lm(afatal_rate ~ tax_increase, USFatalities)
#here I run regression to see if tax increase on beer in 1986-1988 is related with alcohol  fatality rate in traffic
summary(regression_two)
#function summary provides me with results of the regression
interaction_regression <- lm(formula = fatal_rate ~ year * beertax, USFatalities)
#lm formula is a code that runs regression and interaction between fatalities rate and  year and beer tax interaction
interactions::interact_plot(interaction_regression, pred = beertax, modx = year, plot.points =  TRUE)
#here I am plotting the previous regression to visualize my results to better understand the output
summary(interaction_regression)
#running summary to see results of my interaction regression
interaction_regression_two <- lm(formula = afatal_rate ~ year * beertax, USFatalities)
#Interaction regression finding interaction of beertax and years on traffoc fatalities involving alcohol.
interactions::interact_plot(interaction_regression_two, pred = beertax, modx = year, plot.points =  TRUE)
#Plotting interaction effect
summary(interaction_regression_two)
#showimg statistical results of the interaction
#firstly I decided to check differences in fatality rate between states who implemented treatment (increase in taxes) and who did not implemented any treatment based on mean values.
hist(df_treatment_yes$fatal_rate, col = blues9)
#this function generates histogram to see distribution of fatality rate and frequency of observation in group where taxes were increased
hist(df_treatment_no$fatal_rate, col = "yellow" )
#this function generates histogram to see distribution of fatality rate and frequency of observation in group where taxes were not increased
summary(df_treatment_yes$fatal_rate)
#I use summary() to see the results data set analysis where there is increase in taxes and the fatal rate
summary(df_treatment_no$fatal_rate)
#I use summary() to see the results data set analysis where there is increase in taxes and the fatal rate
USFatalities$interval <- ifelse(USFatalities$year == 1982, 0, ifelse(USFatalities$year == 1983, 0, ifelse(USFatalities$year == 1984, 0, ifelse(USFatalities$year == 1985,0, 1))))
#(Paddlebunk, 2018)
#this is to create a new column which shows divides observations into pre and post treatments in terms of time as we know that pre-tax time interval is 1982 till 1985 and and time interval when the tax increase was happening is from 1986 and more
sum(USFatalities$year == 1982)
#I do not need to use pivot_longer() function because I have multiple data for multiple years and also same years have multiple data points -> for instance the code here shows that year 1982 has 48 rows = 48 observations
did_regression <- lm(fatal_rate ~ tax_increase + interval + tax_increase*interval, data = USFatalities)
summary(did_regression)
#in this part of the code I run Diff-in-Diff regression -> Diff-in-diff shows the difference between states that incorporate tax increase and states that did not incorporate tax increase (tax_increase = variable) and pre and post treatment (interval = variable) = so states that did not increase their tax and states that did increase the tax on alcohol and time intervals between pre tax increase and post tax increase -> it shows whether increasing of tax rate decreases or increases fatalities rate in states -> according to the economic theory increase in tax rate on alcohol in states that incorporate the tax increase should decrease traffic fatality rate
#I use summary() to see the results of Diff-in-Diff regression
#because the previous results seems to be mission other intervening variables I decided to add more variables such as jail time and breath controls to see whether adding them decreases the fatality rate
did_regression_extensive <- lm(fatal_rate ~ tax_increase + interval + tax_increase*interval + jail + breath, data = USFatalities)
summary(did_regression_extensive)
#I use summary() to see the results of Diff-in-Diff regression
did_regression_extensive_two <- lm(afatal_rate ~ tax_increase + interval + tax_increase*interval + jail + breath, data = USFatalities)
#difference in difference test to run the analysis
summary(did_regression_extensive_two)
#summary() function to see the results of the runned analysis
panel_df_USF <- pdata.frame(USFatalities, index= c("state", "year"))
#I do it to put year and states in chronological order
head(panel_df_USF)
#this shows me that I put states and years in chronological order to proceed with analysis
plot(USFatalities$fatal_rate, USFatalities$beertax)
#we check for normality and linearity
abline(lm(USFatalities$fatal_rate ~ USFatalities$beertax), col= "blue")
#the linearity assumption seems not o be met
#because the plot is spread it seems that heteroskedasticity has not been met
library(lmtest)
#I download this library to check for Breush-Pagan test which is used to check homoskedasticity
model_assumption_check <- lm(USFatalities$fatal_rate ~ USFatalities$beertax)
#model to be used for
lmtest::bgtest(model_assumption_check)
# running Breush-Pagan test to check homoskedasticity
#(Coding Prof, 2022)
plotmeans(fatal_rate ~ state, USFatalities)
#I want to check if there is a differences in employment data across sectors (states)
model_within <- plm(fatal_rate ~ beertax, data = USFatalities, model = "within")
#statistical regression model and function that is creating fixed effect estimator of beertax
#I decided not to run pooling because within model shows me the fixed effect estimator wich is my main concern
summary(model_within)
#shows me results of the analysis
model_random <- plm(fatal_rate ~ beertax, data = USFatalities, model = "random")
#function to run panel data model for random effect estimator
summary(model_random)
#shows me results of the analysis
phtest(model_within,model_random)
#this is function for hausemann test which checks for covariance
plot(USFatalities$afatal_rate, USFatalities$beertax)
#we check for normality and linearity
#because the plot is spread it seems that heteroskedasticity has not been met
model_assumption_check_two <- lm(USFatalities$afatal_rate ~ USFatalities$beertax)
#model to be used for
lmtest::bgtest(model_assumption_check_two)
# running Breush-Pagan test to check homoskedasticity
#(Coding Prof, 2022)
model_within_two <- plm(afatal_rate ~ beertax, data = USFatalities, model = "within")
#
summary(model_within_two)
#shows me results of the analysis
model_random_two <- plm(afatal_rate ~ beertax, data = USFatalities, model = "random")
#function to run panal data pooled model for random effect estimator
summary(model_random_two)
#shows me results of the analysis
phtest(model_within_two,model_random_two)
#this is function for hausemann test which checks for covariance
setwd("C:/Users/Betty Reinhardova/Desktop/University/Masters/1 - Data analytics/BF_ass")
knitr::opts_chunk$set(echo = TRUE)
```{r}
library(ggplot2)
plotmeans(Q4_Control  ~ Q6_Treatment)
plotmeans(Q4_Control ~ Q6_Treatment)
Q6_Treatment <- BF_STAT$Q6_1
Q4_Control <- BF_STAT$Q4_1
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34 <- Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34[, 18:ncol(Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34)]
#Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34 <- Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34[, 18:ncol(Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34)]
BF_STAT <- BF_STAT[-2,]
BF_STAT <- Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34
head(Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34.csv)
head("Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34.csv")
install.packages("tidyverse")
load("Consumer_preferences_between_saving_and_investing_survey_March_26_2023_05_34.csv")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
